<!doctype html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>Adding Generative AI to your Workflow with Google Gemini</title>

		<link rel="stylesheet" href="dist/reset.css">
		<link rel="stylesheet" href="dist/reveal.css">
		<link rel="stylesheet" href="dist/theme/black.css">

		<!-- Theme used for syntax highlighted code -->
		<link rel="stylesheet" href="plugin/highlight/monokai.css">

		<style>
		.twocol {
			display: grid;
			grid-template-columns: 80% 20%;
		}
		</style>

	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<section data-background="img/matrix.jpg" data-background-opacity="0.3">
				<h1>Adding Generative AI to your Workflow</h1><h2>with Google Gemini</h2>
				</section>

				<section>
				<div class="twocol">
				<div>
					<h2>Me</h2>
					<ul style="width: 100% !important">
					<li>Raymond Camden</li>
					<li>Developer Evangelist for Hire!</li>
					<li>üï∏Ô∏è raymondcamden.com</li>
					<li>‚úâÔ∏è raymondcamden@gmail.com</li>
					<li>@raymondcamden.com (Bluesky)</li>
					<li>@raymondcamden (Mastodon)</li>
					</ul>
				</div>
				<div>
					<img src="img/ray_tiger.jpg" style="max-width:70%">
				</div>
				</div>
				</section>

				<section>
					<img src="img/qr.png">
					<a href="https://github.com/cfjedimaster/gemini-ai-preso" target="_new">github.com/cfjedimaster/gemini-ai-preso</a>
				</section>

				<section data-background="img/fire.png" data-background-opacity="0.3">
					<h2>Assumptions and Warnings</h2>
				</section>

				<section>
				<h2>What You Know, What I Know</h2>
				<ul>
				<li class="fragment">What Generative AI is (<span style="color: yellow;font-weight:bold">high level!!</span>)</li>
				<li class="fragment">Node.js, Python, etc (basic level)</li>
				<!--
				<li class="fragment">Noob on Stage (me, not you)</li>
				-->
				<aside class="notes">
				Best way I can describe my current skill level - I have a real good idea now of what I don't know.
				Also, I know enough to be dangerous! Woot!
				</aside>
				</section>

				<section>
				<h2>TLDR: Good News</h2>
				<p class="fragment">
				Getting a key, writing the code, it's simple!
				</p>
				</section>

				<section>
				<h2>TLDR: Bad News</h2>
				<p class="fragment">
				*Correctly* using Gen AI is way more complex and "prompt engineering" is no joke.
				</p>
				</section>


				<section>
				<h2>Google Gemini</h2>
				<ul>
				<li class="fragment">The artist formally known as Bard (Feb 2023)</li>
				<li class="fragment">Relaunched as Gemini (Dec 2023)</li>
				<li class="fragment">API access in October (PaLM - text only)</li>
				<li class="fragment">Gemini API (also Dec 2023)</li>
				<li class="fragment">Don't forget: Gemini App (gemini.google.com)</li>
				<li class="fragment">Also... Vertex</li>
				</ul>
				<aside class="notes">
Source: https://en.wikipedia.org/wiki/Gemini_(chatbot)				
After an "underwhelming" February 8 livestream in Paris showcasing Bard, Google's stock fell eight percent, equivalent to a $100 billion loss in market valu				

I'm going to ignore Vertex until the end of the preso because it's just going to be confusing - trust me.
				</aside>
				</section>

				<section>
				<h2>Getting Started</h2>
				<ul>
				<li class="fragment"><a href="https://ai.google.dev/" target="_new">ai.google.dev</a></li>
				<li class="fragment"><a href="https://aistudio.google.com/" target="_new">aistudio.google.com</a></li>
				<li class="fragment"><a href="https://ai.google.dev/gemini-api/docs/" target="_new">Docs</a></li>
				<li class="fragment"><a href="https://discuss.ai.google.dev/" target="_new">Support Forum</a></li>
				</ul>
				<aside class="notes">
				Marketing pages, good overview, etc. Examples. 
				</aside>
				</section>

				<section>
				<h2>Models</h2>
				<ul>
				<li class="fragment">Gemini 1.5 Pro</li>
				<li class="fragment">Gemini 2.0 Flash (quicker, not as deep) üÜï</li>
				<li class="fragment">Gemini 2.0 Flash-Lite (optimized for cost + latency)</li>
				<li class="fragment">There's more and...</li>
				<li class="fragment">Changing... like often</li>
				<li class="fragment"><a href="https://ai.google.dev/gemini-api/docs/models/gemini" target="_new">More at docs</a></li>
				</ul>
				</section>

				<!--
				<section>
				<h2>1.5 Pro</h2>
				<ul>
				<li class="fragment">Huge Context (2M tokens)</li>
				<li class="fragment">2 hours of video</li>
				<li class="fragment">19 hours of audio</li>
				<li class="fragment">7200 images</li>
				<li class="fragment">2000 pages of text (approx)</li>
				<li class="fragment">60K lines of code (approx)</li>
				</ul>
				</section>
				-->

				<section>
				<h2>Code</h2>
				<ul>
				<li class="fragment">REST API</li>
				<li class="fragment">Python</li>
				<li class="fragment">Node</li>
				<li class="fragment">Go</li>
				<li class="fragment">Web ü§î</li>
				<li class="fragment">Dart</li>
				<li class="fragment">Flutter</li>
				<li class="fragment">Android</li>
				<li class="fragment">Swift</li>
				</ul>
				</section>

				<section>
				<h2>Actually Using It</h2>
				<ul>
				<li class="fragment">Step 1: Get a Key</li>
				<li class="fragment">Step 2: </li>
				<li class="fragment">Step 3: Profit!</li>
				</ul>
				</section>

				<section>
				<img src="img/getkey1.png">
				</section>

				<section>
				<img src="img/getkey2.png">
				</section>

				<section>
				<img src="img/getkey3.png">
				</section>

				<section>
				<img src="img/getkey4.png">
				</section>

				<section>
				<pre><code>
curl \
  -H 'Content-Type: application/json' \
  -d '{"contents":[{"parts":[{"text":"Write a story about a magic backpack"}]}]}' \
  -X POST 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=YOUR_API_KEY'
				</code></pre>
				<p>
				Show demos/curh.sh
				</p>
				<aside class="notes">
				show demos/curl.sh
				</aside>
				</section>

				<section>
				<pre class="language-json"><code data-trim>
{
  "candidates": [
    {
      "content": {
        "parts": [
          {
            "text": "Maya found the backpack in the attic of her grandmother's rambling Victorian house. It was tucked away in a cobweb-draped corner, behind a dusty rocking horse and a stack of chipped porcelain dolls. The backpack was unremarkable at first glance: faded brown canvas with worn leather straps. But as she lifted it, a faint shimmer danced across its surface, and a whisper of warmth tickled her fingers.\n\nIntrigued, Maya brushed off the dust and carried it downstairs. Her grandmother, Nana Willow, was humming by the fireplace, knitting a scarf that stretched seemingly endlessly.\n\n\"Nana, look what I found!\" Maya exclaimed, holding up the backpack.\n\nNana Willow's eyes twinkled. \"Ah, the Wanderer's Pack. I wondered when someone would find it again.\"\n\n\"The Wanderer's Pack? What is it?\"\n\nNana Willow chuckled. \"Let's just say it's... helpful. It holds whatever you need, whenever you need it. But be warned, Maya. It only gives what is truly necessary, not always what you desire.\"\n\nMaya, a pragmatic girl who loved hiking and the outdoors, couldn't resist. The next morning, she packed a lunch, a water bottle, and a map into her usual backpack, and then, on a whim, she slung the Wanderer's Pack over her other shoulder.\n\nShe set off on her favorite trail, a challenging climb that rewarded with breathtaking views from the mountain's peak. Halfway up, her water bottle ran dry, and her legs began to ache. Remembering the Wanderer's Pack, she reached inside, expecting to find a refreshing drink. Instead, her fingers brushed against a small, smooth stone.\n\nDisappointed, she pulled it out. It was an ordinary river stone, cool and slightly damp. Scowling, she almost tossed it aside, but then she noticed a small, trickling spring hidden beneath a mossy boulder. Without the stone, she wouldn't have paused to look. The spring offered the freshest, coldest water she'd ever tasted.\n\nLater, as she navigated a particularly steep and rocky section, she stumbled, twisting her ankle. Fear flashed through her, knowing she was miles from help. She desperately reached into the Wanderer's Pack. This time, she pulled out not a bandage, but a short, sturdy walking stick. It wasn't what she wanted, but it provided the support she needed to hobble her way to a more stable area.\n\nAs she reached the summit, exhausted but exhilarated, she finally understood. The Wanderer's Pack didn't grant wishes; it provided what she truly *needed* to overcome her challenges.\n\nOver the next few weeks, Maya used the backpack often. She needed inspiration for a school project and found a collection of bird feathers that sparked an idea for a stunning nature diorama. She yearned for a new bike and found a rusty wrench that she used to fix up an old one she‚Äôd abandoned in the garage.\n\nOne day, her best friend, Liam, was devastated after losing his dog, Buster. Maya desperately wanted to cheer him up, to magically bring Buster back. She reached into the backpack with fervent hope. She pulled out‚Ä¶ nothing. The bag was empty.\n\nHeartbroken, she sat beside Liam, offering a shoulder to cry on and a listening ear. She realized then that the greatest need wasn't always a tangible object. Sometimes, it was just presence, empathy, and unwavering support.\n\nThat night, she sat by the fire with Nana Willow.\n\n\"I understand now,\" Maya said, \"The Wanderer's Pack gives you what you need, not what you want. But sometimes, what you need is‚Ä¶ nothing.\"\n\nNana Willow smiled knowingly. \"Sometimes, Maya, the greatest gifts are the ones we already possess ‚Äì our strength, our compassion, and our ability to be there for each other.\"\n\nMaya returned the Wanderer's Pack to its place in the attic. She knew it would always be there, a silent reminder that true magic wasn't about instant gratification, but about resourcefulness, resilience, and the enduring power of human connection. And sometimes, that was all you truly needed.\n"
          }
        ],
        "role": "model"
      },
      "finishReason": "STOP",
      "avgLogprobs": -0.53034632891074
    }
  ],
  "usageMetadata": {
    "promptTokenCount": 7,
    "candidatesTokenCount": 870,
    "totalTokenCount": 877,
    "promptTokensDetails": [
      {
        "modality": "TEXT",
        "tokenCount": 7
      }
    ],
    "candidatesTokensDetails": [
      {
        "modality": "TEXT",
        "tokenCount": 870
      }
    ]
  },
  "modelVersion": "gemini-2.0-flash"
}

				</code></pre>
				<p>
				<a href="https://ai.google.dev/api/rest/v1/GenerateContentResponse" target="_new">Reference for Response</a>
				</p>
				</section>

				<section>
				<h2>AI Studio</h2>
				<ul>
				<li class="fragment">Let's you create, and save, prompts</li>
				<li class="fragment">Super, super important for testing and tweaking</li>
				<li class="fragment">Then let's you generate code</li>
				</ul>
				</section>

				<section>
					<h2>AI Studio Demo</h2>
					<p>
					Show AI Studio, code output, and then first
					</p>
					<aside class="notes">
Open Studio.
Show create new and discuss the differences.
Start simple: Why is the sky blue, and how are cats involved in that process?

Note how it's got the response

Note how its a chat session 

Talk about how you tweak the prompt: You should answer at a level appropriate for a high schooler and even if cats aren't really involved, you should make up a way they are.

Show Get Code - note how it has the whole prompt.

Show first.js
call out the important bits
comment out .text(), show full json instead 

					</aside>
				</section>

			<section>

				<section>
					<h2>Node</h2>
				</section>

				<section>
				<h2>Node SDK</h2>
				<ul>
				<li class="fragment"><code>npm install @google/generative-ai</code></li>
				<li class="fragment">Repo: <a href="https://github.com/google-gemini/generative-ai-js" target="_blank">github.com/google-gemini/generative-ai-js</a></li>
				<li class="fragment">Better docs: <a href="https://github.com/google-gemini/generative-ai-js/blob/main/docs/reference/main/generative-ai.md" target="_blank">github.com/google-gemini/generative-ai-js/blob/main/docs/reference/main/generative-ai.md</a></li>
				</ul>
				<aside class="notes">
				You can find docs there but you have to dig a bit
				</aside>
				</section>

				<section>
				<pre class="language-js"><code data-trim data-line-numbers="">
// Adapted from Quick Start
// Load SDK and initialize with key
const { GoogleGenerativeAI } = require("@google/generative-ai");

const genAI = new GoogleGenerativeAI("YOUR_API_KEY");
const model = genAI.getGenerativeModel({ model: "gemini-2.0-flash" });
				</code></pre>
				</section>

				<section>
				<pre class="language-js"><code data-trim data-line-numbers="6,7">
const { GoogleGenerativeAI } = require("@google/generative-ai");

const genAI = new GoogleGenerativeAI("YOUR_API_KEY");
const model = genAI.getGenerativeModel({ model: "gemini-2.0-flash" });

//specify a prompt
const prompt = "Explain cats";
				</code></pre>
				</section>

				<section>
				<pre class="language-js"><code data-trim data-line-numbers="8-10">
const { GoogleGenerativeAI } = require("@google/generative-ai");

const genAI = new GoogleGenerativeAI("YOUR_API_KEY");
const model = genAI.getGenerativeModel({ model: "gemini-2.0-flash" });

const prompt = "Explain cats";

// pass prompt and dump result
const result = await model.generateContent(prompt);
console.log(result.response.text());
				</code></pre>
				</section>

				<section>
					<h2>Demo</h2>
					<p>
					Show second.js
					</p>
				</section>

			</section>

			<section>

				<section>
					<h2>Python</h2>
				</section>

				<section>
				<h2>Python SDK</h2>
				<ul>
				<li class="fragment"><code>pip install -q -U google-genai</code></li>
				<li class="fragment">Repo: <a href="https://pypi.org/project/google-genai/" target="_blank">pypi.org/project/google-genai/</a></li>

				</ul>
				<aside class="notes">
				</aside>
				</section>

				<section>
				<pre class="language-python"><code data-trim data-line-numbers="">
# Adapted from Quick Start

from google import genai

client = genai.Client(api_key="YOUR_API_KEY")
				</code></pre>
				</section>

				<section>
				<pre class="language-python"><code data-trim data-line-numbers="6,9">
# Adapted from Quick Start

from google import genai

client = genai.Client(api_key="YOUR_API_KEY")
response = client.models.generate_content(
    model="gemini-2.0-flash", contents="Explain how AI works"
)
print(response.text)
				</code></pre>
				</section>

				<section>
					<h2>Demo</h2>
					<p>
					Show second.py
					</p>
				</section>

			</section>


				<section>
				<h2>Multimodal</h2>
				<ul>
				<li class="fragment">Just means multiple types of input</li>
				<li class="fragment">Images, text files, and video</li>
				<li class="fragment">*Can* be inlined as Base64, if less than 20 megs</li>
				<li class="fragment">Files API</li>
				<li class="fragment">Files API max - 20 gigs per project, 2 gig per file</li>
				<li class="fragment">Files API - auto delete after 2 days (you can manually delete as well)</li>
				</ul>
				<aside class="notes">
				</aside>
				</section>

				<section>
				<h2>File Type Specifics</h2>
				<ul>
				<li class="fragment">Image: PNG, JPG, WEBP, HEIC, HEIF</li>
				<li class="fragment">Audio: WAV, MP3, AIFF, AAC, OGG, FLAC</li>
				<li class="fragment">Note - Gemini understands 'non-speech' parts (ie, sounds)</li>
				<li class="fragment">Video: MP4, MPEG, MOV, AVI, X-FLV, MPG, WEBM, WMV, 3GPP</li>
				<li class="fragment">Note - for video, image frames are extracted (1 per second)</li>
				<li class="fragment">Docs: PDF, TXT, Markdown, CSV (<a href="https://ai.google.dev/gemini-api/docs/document-processing?lang=python#technical-details" target="_blank">more</a>)</li>
				<!--
				<li class="fragment">Details: <a href="https://ai.google.dev/gemini-api/docs/prompting_with_media#supported_file_formats" target="_new">Supported file formats</a></li>
				-->
				</ul>
				</section>

				<section>
					<h2>AI Studio Demo - MM</h2>
					<p>
					In AI Studio, upload the cat!
					</p>
					<aside class="notes">
Open Studio. Pick cat.
For code, show image1.js
					</aside>
				</section>

				<section>
					<h2>Code Demo - MM</h2>
					<p>
					Show image1, and possibly image2 and the fun one (time dependent)
					</p>
					<aside class="notes">
For code, show image1.js
					</aside>
				</section>

				<section>
				<h2>Chat</h2>
				<ul>
				<li class="fragment">Why? Context</li>
				<li class="fragment">First and Foremost: Nothing Special</li>
				<li class="fragment">Chat is just prompts that... keep... growing</li>
				<li class="fragment">You manage the history...</li>
				<li class="fragment">Use the SDK! ‚ú®</li>
				</ul>
				</section>

				<section>
					<h2>Demo</h2>
					<p> 
					Show chat
					</p>
				</section>

				<section>
				<h2>System Instructions</h2>
				<ul>
				<li class="fragment">Provide context about how the model should respond</li>
				<li class="fragment">Think persona, style, as well as output</li>
				<li class="fragment">Can be used in the prompt as well</li>
				</ul>
				</section>

				<section>
				<h2>Node</h2>
				<pre><code class="language-javascript">
// https://ai.google.dev/gemini-api/docs/text-generation?lang=node#system-instructions
const model = genAI.getGenerativeModel({
  model: "gemini-1.5-flash",
  systemInstruction: "You are a cat. Your name is Neko.",
});
</code></pre>
				</section>

				<section>
				<h2>Python</h2>
				<pre><code class="language-python">
# https://ai.google.dev/gemini-api/docs/text-generation?lang=python#system-instructions
sys_instruct="You are a cat. Your name is Neko."
client = genai.Client(api_key="GEMINI_API_KEY")

response = client.models.generate_content(
    model="gemini-2.0-flash",
    config=types.GenerateContentConfig(
        system_instruction=sys_instruct),
    contents=["your prompt here"]
)				</code></pre>
				</section>

				<section>
					<h2>Demo</h2>
					<p> 
					Show si1 and si2
					</p>
				</section>

				<section>
				<h2>Shaping Responses</h2>
				<ul>
				<li class="fragment">Your prompt can ask for JSON</li>
				<li class="fragment">So can system instructions</li>
				<li class="fragment">Be specific</li>
				<li class="fragment">There's also a response type setting...</li>
				</ul>
				</section>

				<section>
				<h2>Shaping Responses - 2</h2>
				<ul>
				<li class="fragment">By default, Gemini returns text in Markdown</li>
				<li class="fragment">Even if you ask for JSON, it's JSON... in Markdown</li>
				<li class="fragment">Setting the response type is essential!</li>
				</ul>
				</section>

				<section>
				<h2>Node</h2>
				<pre><code class="language-javascript">
const generationConfig = {
	temperature: 0.9,
	topK: 1,
	topP: 1,
	maxOutputTokens: 2048,
	response_mime_type:'application/json'
};

await model.generateContent({
	contents: [ { role: "user", [ {text:"prompt"} ] } ], 
	generationConfig
});
				</code></pre>
				</section>

				<section>
				<h2>Python</h2>
				<pre><code class="language-python">
response = client.models.generate_content(
  model='gemini-2.0-flash',
  contents='Tell me a story in 100 words.',
  config=types.GenerateContentConfig(
      system_instruction='you are a story teller for kids under 5 years old',
      response_mime_type= 'application/json'
   ),
)

				</code></pre>
				</section>

				<section>
					<h2>Demo</h2>
					<p>
					Show json_response
					</p>
					<aside class="notes">
					File is json_response.js, just text 
					"What are the top reasons cats are good pets?"
					then show the second one
					</aside>
				</section>

				<section>
				<h2>Shaping Responses - 3</h2>
				<ul>
				<li class="fragment">Let's you specify *exactly* what you want</li>
				<li class="fragment">Subset of OpenAPI 3.0 Schema object</li>
				<li class="fragment">Used to be JSON Schema</li>
				</ul>
				</section>

				<section>
					<h2>Demo</h2>
					<p>
					Show json_response3 
					</p>
					<aside class="notes">
					File is json_response.js, just text 
					"What are the top reasons cats are good pets?"
					then show the second one
					</aside>
				</section>

				<section>
					<h2>Image Generation</h2>
					<ul>
					<li class="fragment">Super, super new (like 2-3 weeks ago)</li>
					<li class="fragment">Two model options - Gemini Flash 2.0 Experimental and Imagen</li>
					<li class="fragment">Supports generating new images and editing existing images</li>
					</ul>
				</section>

				<section>
					<h2>Image Generation - Gemini vs Imagen</h2>
					<ul>
					<li class="fragment">Gemini best for text *and* images</li>
					<li class="fragment">Imagen has higher quality and more control over size</li>
					<li class="fragment">Gemini is free üòÄ</li>
					<li class="fragment"><a href="https://ai.google.dev/gemini-api/docs/image-generation#choose-a-model" target="_blank">More Info</a></li>
					</ul>
				</section>


				<section>
				<h2>Python</h2>
				<pre><code class="language-python">
client = genai.Client(api_key=os.environ["GEMINI_API_KEY"])

response = client.models.generate_content(
	model="models/gemini-2.0-flash-exp",
	contents="a bunch of kittens playing in the grass",
	config=types.GenerateContentConfig(response_modalities=['Text', 'Image'])
)
				</code></pre>
				</section>

				<section>
				<img src="img/kittens.png">
				</section>


				<section>
					<h2>Demo</h2>
					<p>
					Show make_image
					</p>
					<aside class="notes">
					</aside>
				</section>

				<section>

					<section>
						<h2>Examples</h2>
					</section>

					<section>
						<h2>Movie Recommendations</h2>
						<ul>
						<li>Get user's last movie watched</li>
						<li>Pass it to Gemini and ask - what next?</li>
						<li>Email suggestions to user</li>
						<li><a href="https://www.raymondcamden.com/2024/04/26/automating-movie-recommendations-with-generative-ai-and-pipedream" target="_new">Blog post</a></li>
						</ul>
					</section>

					<section>
						<h2>D&D Recommendation</h2>
						<ul>
						<li>Let users roll for attributes</li>
						<li>Pass it to Gemini and ask - what class makes the most sense?</li>
						<li><a href="https://www.raymondcamden.com/2024/04/11/using-genai-to-help-pick-your-d--d-class" target="_new">Blog post</a></li>
						</ul>
					</section>

					<section>
					<h2>Blackjack Help</h2>
					<ul>
					<li>Given a web-based Blackjack game...</li>
					<li>And the status of the game...</li>
					<li>Can AI help you play?</li>
					<li><a href="https://www.raymondcamden.com/2023/11/09/can-genai-help-you-win-in-vegas" target="_new">Blog post</a></li>
					</ul>
					</section>

				</section>

				<section>
					<h2>Things Not Covered</h2>
					<ul>
					<li class="fragment">Function Calling (<a href="https://ai.google.dev/gemini-api/docs/function-calling" target="_new">Docs</a>)</li>
					<li class="fragment">Model Tuning (<a href="https://ai.google.dev/gemini-api/docs/model-tuning" target="_new">Docs</a>)</li>
					<li class="fragment">Prompt Writing (<a href="https://ai.google.dev/gemini-api/docs/prompting-intro" target="_new">Docs</a>)</li>
					<li class="fragment"><a href="https://github.com/google-gemini/cookbook" target="_new">Gemini API Cookbook (Notebooks)</a></li>
					</ul>
				</section>

				<section>
					<h2>Vertex - what the diff?</h2>
					<ul>
					<li class="fragment">Vertex has no free tier</li>
					<li class="fragment">AI Studio's free tier may use your data for training</li>
					<li class="fragment">AI Studio isn't available (region wise) as much as Vertex</li>
					<li class="fragment">Vertex requires Google Cloud auth models</li>
					<li class="fragment">More info at <a href="https://cloud.google.com/vertex-ai" target="_new">https://cloud.google.com/vertex-ai</a></li>
					<li class="fragment">Thank you <a href="https://prisoner.com/" target="_new">Allen Firstenberg</a></li>
					</ul>
				</section>

				<!-- Chrome Nano section -->
				<!--
				<section>
					<img src="img/more.jpg">
				</section>

				<section>
				<h2>AI... in the browser?</h2>
				<ul>
				<li class="fragment">Gemini Nano for Chrome</li>
				<li class="fragment">Web platform<sup>*</sup> APIs for GenAI</li>
				<li class="fragment">Introductory blog <a href="https://developer.chrome.com/docs/ai/built-in" target="_new">post</a></li>
				<li class="fragment">EAP only - sign up <a href="https://docs.google.com/forms/d/e/1FAIpQLSfZXeiwj9KO9jMctffHPym88ln12xNWCrVkMY_u06WfSTulQg/viewform" target="_blank">here</a></li>
				</ul>

				<p class="fragment">Support in Chrome only, for now, but progressive enhancement is your friend!</p>
				</section>

				<section>
				<h2>Chrome Built-in AI</h2>
				<ul>
				<li class="fragment">Supports models focused on specific tasks...
					<ul>
					<li class="fragment">Translation and Language Detection</li>
					<li class="fragment">Rewriting/Writing</li>
					<li class="fragment">Summarization</li>
					</ul>
				</li>
				<li class="fragment">Supports sessions (can be saved/restored manually)</li>
				<li class="fragment">Supports system instructions and other tweaks</li>
				<li class="fragment">Supports streaming responses</li>
				</ul>
				</section>

				<section>
				<h2>Chrome Built-in AI</h2>
				<ul>
				<li class="fragment">Does require downloads for models, etc...</li>
				<li class="fragment">Provides event hooks for you to monitor</li>
				<li class="fragment">This can be a bit slow</li>
				</ul>
				</section>

				<section>
				<h2>Chrome Built-in AI</h2>
				<ul>
				<li class="fragment">Multimodal - NOT supported (currently)</li>
				<li class="fragment">Shaping output - NOT supported (currently, mostly)</li>
				</ul>
				</section>

				<section>
				<img src="img/dragons.jpg">
				</section>

				<section>
				<pre class="language-js"><code data-trim data-line-numbers="">
// do we support it at all?
if(!window.ai) return;
				</code></pre>
				</section>

				<section>
				<pre class="language-js"><code data-trim data-line-numbers="4-6">
// do we support it at all?
if(!window.ai) return;

// is the model actually ready? 
let ready = (await window.ai.languageModel.capabilities()).available;
if(ready !== 'readily') return;
				</code></pre>
				</section>

				<section>
				<pre class="language-js"><code data-trim data-line-numbers="8-9">
// do we support it at all?
if(!window.ai) return;

// is the model actually ready? 
let ready = (await window.ai.languageModel.capabilities()).available;
if(ready !== 'readily') return;

// this is what you work with...
let session = await window.ai.languageModel.create();

				</code></pre>
				</section>

				<section>
				<pre class="language-js"><code data-trim data-line-numbers="11-12">
// do we support it at all?
if(!window.ai) return;

// is the model actually ready? 
let ready = (await window.ai.languageModel.capabilities()).available;
if(ready !== 'readily') return;

// this is what you work with...
let session = await window.ai.languageModel.create();

// will return markdown
let result = await session.prompt("why are cats so... cat?");

				</code></pre>
				</section>
				<section>
					<h2>Demo</h2>
					<p>
					simple_prompt.html, simple_summary.html
					</p>
				</section>
				-->

				<section>
					<h2>Questions?</h2>
					<img alt="questions?" src="img/cat_qa.png">
				</section>


			</div>
		</div>

		<script src="dist/reveal.js"></script>
		<script src="plugin/notes/notes.js"></script>
		<script src="plugin/markdown/markdown.js"></script>
		<script src="plugin/highlight/highlight.js"></script>
		<script>
			// More info about initialization & config:
			// - https://revealjs.com/initialization/
			// - https://revealjs.com/config/
			Reveal.initialize({
				hash: true,
				slideNumber: "c/t",
				// Learn about plugins: https://revealjs.com/plugins/
				plugins: [ RevealMarkdown, RevealHighlight, RevealNotes ]
			});
		</script>
	</body>
</html>
